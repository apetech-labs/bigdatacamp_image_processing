{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a112d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02169277",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b34667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input datas\n",
    "train_dataset.data.shape, test_dataset.data.shape\n",
    "\n",
    "# output datas\n",
    "train_dataset.targets.shape, test_dataset.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f370ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13578cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = 4\n",
    "for it_sam, _sample in enumerate(train_dataset.data[:10]):\n",
    "\n",
    "    cur_idx = it_sam%plot_size+1\n",
    "\n",
    "    plt.subplot(1, plot_size, cur_idx)\n",
    "\n",
    "    _sample_target = train_dataset.targets[it_sam]\n",
    "    plt.title(_sample_target.item())\n",
    "    plt.imshow(_sample, 'gray')\n",
    "\n",
    "\n",
    "    if cur_idx == plot_size:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7914376",
   "metadata": {},
   "source": [
    "# model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_fcn(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_input, model_output):\n",
    "        super(Mnist_fcn, self).__init__()\n",
    "        \n",
    "        #28 x 28 = 784\n",
    "        # layer\n",
    "        self.fc = nn.Linear(model_input, 64) # learning weight, bias\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, model_output)\n",
    "        \n",
    "        #activation \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "       # Cross Entropy Loss --> softmax 생략\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf20466",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_fcn(28*28, 1) # Cross entropy 1 [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] # MSE 2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3290eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=((1, 784)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ebfaf",
   "metadata": {},
   "source": [
    "# model learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3869b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2 #0.01\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8cf2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for _epoch in range(epochs):\n",
    "    for it_batch, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.reshape([100, -1])\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # label\n",
    "        labels = labels.reshape([100, -1])\n",
    "        labels = labels.type(torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if (it_batch+1) % 100 == 0 :\n",
    "            print(f'epoch{_epoch}, batch{it_batch}, loss{loss.item()}' )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                correct_ = 0\n",
    "                total_ = 0\n",
    "\n",
    "                for it_batch, (images, labels) in enumerate(test_loader):\n",
    "                    images = images.reshape([100, -1])\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    labels = labels.reshape([100, -1])\n",
    "                    labels = labels.type(torch.float32)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    # pred=torch.argmax(outputs, axis=1)\n",
    "                     \n",
    "\n",
    "                    # total_ += pred.shape[0]\n",
    "                    # correct_ += (labels==pred).sum()\n",
    "                    total_ += outputs.shape[0]\n",
    "                    correct_ += torch.sum(torch.round(outputs) == labels).item()\n",
    "\n",
    "\n",
    "                acc = correct_/total_ * 100\n",
    "                print(f'acc:{acc:.2f}, correct:{correct_}, total:{total_}')\n",
    "                \n",
    "                model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438c909",
   "metadata": {},
   "source": [
    "# calc Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    correct_ = 0\n",
    "    total_ = 0\n",
    "\n",
    "    for it_batch, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape([100, -1])\n",
    "        labels = labels.reshape([100, -1])\n",
    "        outputs = model(images)\n",
    "        total_ += outputs.shape[0]\n",
    "        correct_ += torch.sum(torch.round(outputs) == labels).item()\n",
    "\n",
    "#         pred=torch.argmax(outputs, axis=1)\n",
    "\n",
    "#         total_ += pred.shape[0]\n",
    "#         correct_ += (labels==pred).sum()\n",
    "    \n",
    "    \n",
    "    acc = correct_/total_ * 100\n",
    "    print(f'acc{acc:.2f}, correct{correct_}, total{total_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8692e4a",
   "metadata": {},
   "source": [
    "# predict display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_torch_ret(inputs, targets, predicts, plot_size=4):\n",
    "    inputs = inputs.permute(0, 2, 3, 1)\n",
    "\n",
    "    for it_sam, _sample in enumerate(inputs):\n",
    "\n",
    "\n",
    "        cur_idx = it_sam%plot_size+1\n",
    "        plt.subplot(1, plot_size, cur_idx)\n",
    "\n",
    "        _sample_target = targets[it_sam]\n",
    "        _sample_predict = predicts[it_sam] \n",
    "        \n",
    "        if _sample_predict != _sample_target :\n",
    "            print('################# incorrect ##############')\n",
    "        _title = f'gt:{_sample_target.item()}, p:{_sample_predict.item()}'\n",
    "        plt.title(_title)\n",
    "        plt.imshow(_sample, 'gray')\n",
    "\n",
    "\n",
    "        if cur_idx == plot_size:\n",
    "#             plt.figure(figsize=(12, 12))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_test = iter(test_loader)\n",
    "\n",
    "images, labels = next(iter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92863ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images.reshape([100, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f280c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.round(outputs) == labels.reshape([-1, 1]) ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff959ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predicts = torch.argmax(outputs, axis=1)\n",
    "predicts = torch.round(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc19810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_torch_ret(images, labels, predicts, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fbc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
