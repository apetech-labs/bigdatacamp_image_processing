{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c85618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4337ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'mps'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ca163",
   "metadata": {},
   "source": [
    "# data transform --> norm, type casting, crop, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fdb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 0~1 numpy -> tensor,\n",
    "    # 0 ~ 1 0-0.5/0.5:-1 (1-0.5)/0.5, -1~1\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    # 좌우 반전\n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 0~1 numpy -> tensor,\n",
    "    # 0 ~ 1 0-0.5/0.5:-1 (1-0.5)/0.5, -1~1\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cfdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174d1e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27fb497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), 50000, [6, 9, 9, 4, 1, 1, 2, 7, 8, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), 50000, [6, 9, 9, 4, 1, 1, 2, 7, 8, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape, len(trainset.targets), trainset.targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c34723d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9d4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c93dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d2d091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3, 32, 32]), torch.Size([100]), tensor(-1.), tensor(1.))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3, 32, 32]), torch.Size([100]), tensor(-1.), tensor(1.))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape, images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce99d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].permute(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[1].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96904bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min(), img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(classes[labels[1].item()])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3bbc37",
   "metadata": {},
   "source": [
    "# model init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90417b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cifar_cnn, self).__init__()\n",
    "        # layer\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(3,3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=4, out_channels=16, kernel_size=(3,3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # 32 x 5 x 5\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(0.5), \n",
    "            nn.Linear(32*5*5, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(32, 10)\n",
    "\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 순전파\n",
    "        \n",
    "        out = self.conv_layer(x)\n",
    "        # bx16x5x5 --> 1d --> 400\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        \n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47c1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cifar_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbca1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3558a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 30, 30]             112\n",
      "              ReLU-2            [-1, 4, 30, 30]               0\n",
      "            Conv2d-3           [-1, 16, 28, 28]             592\n",
      "              ReLU-4           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-5           [-1, 16, 14, 14]               0\n",
      "            Conv2d-6           [-1, 32, 12, 12]           4,640\n",
      "              ReLU-7           [-1, 32, 12, 12]               0\n",
      "            Conv2d-8           [-1, 32, 10, 10]           9,248\n",
      "              ReLU-9           [-1, 32, 10, 10]               0\n",
      "        MaxPool2d-10             [-1, 32, 5, 5]               0\n",
      "          Dropout-11                  [-1, 800]               0\n",
      "           Linear-12                   [-1, 64]          51,264\n",
      "             ReLU-13                   [-1, 64]               0\n",
      "           Linear-14                   [-1, 32]           2,080\n",
      "             ReLU-15                   [-1, 32]               0\n",
      "           Linear-16                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 68,266\n",
      "Trainable params: 68,266\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.40\n",
      "Params size (MB): 0.26\n",
      "Estimated Total Size (MB): 0.68\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 30, 30]             112\n",
      "              ReLU-2            [-1, 4, 30, 30]               0\n",
      "            Conv2d-3           [-1, 16, 28, 28]             592\n",
      "              ReLU-4           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-5           [-1, 16, 14, 14]               0\n",
      "            Conv2d-6           [-1, 32, 12, 12]           4,640\n",
      "              ReLU-7           [-1, 32, 12, 12]               0\n",
      "            Conv2d-8           [-1, 32, 10, 10]           9,248\n",
      "              ReLU-9           [-1, 32, 10, 10]               0\n",
      "        MaxPool2d-10             [-1, 32, 5, 5]               0\n",
      "          Dropout-11                  [-1, 800]               0\n",
      "           Linear-12                   [-1, 64]          51,264\n",
      "             ReLU-13                   [-1, 64]               0\n",
      "           Linear-14                   [-1, 32]           2,080\n",
      "             ReLU-15                   [-1, 32]               0\n",
      "           Linear-16                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 68,266\n",
      "Trainable params: 68,266\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.40\n",
      "Params size (MB): 0.26\n",
      "Estimated Total Size (MB): 0.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=((3, 32, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119d9e5",
   "metadata": {},
   "source": [
    "# model learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a601ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 #1e-2\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5698d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch:29, loss2.1021535396575928\n",
      "epoch:0, batch:29, loss2.1021535396575928\n",
      "acc20.41, correct2041, total10000\n",
      "acc20.41, correct2041, total10000\n",
      "epoch:0, batch:59, loss2.0212440490722656\n",
      "epoch:0, batch:59, loss2.0212440490722656\n",
      "acc25.76, correct2576, total10000\n",
      "acc25.76, correct2576, total10000\n",
      "epoch:0, batch:89, loss1.864848017692566\n",
      "epoch:0, batch:89, loss1.864848017692566\n",
      "acc27.33, correct2733, total10000\n",
      "acc27.33, correct2733, total10000\n",
      "epoch:0, batch:119, loss1.9393582344055176\n",
      "epoch:0, batch:119, loss1.9393582344055176\n",
      "acc29.50, correct2950, total10000\n",
      "acc29.50, correct2950, total10000\n",
      "epoch:0, batch:149, loss1.8619422912597656\n",
      "epoch:0, batch:149, loss1.8619422912597656\n",
      "acc31.08, correct3108, total10000\n",
      "acc31.08, correct3108, total10000\n",
      "epoch:0, batch:179, loss2.011519193649292\n",
      "epoch:0, batch:179, loss2.011519193649292\n",
      "acc30.95, correct3095, total10000\n",
      "acc30.95, correct3095, total10000\n",
      "epoch:0, batch:209, loss1.8934205770492554\n",
      "epoch:0, batch:209, loss1.8934205770492554\n",
      "acc32.79, correct3279, total10000\n",
      "acc32.79, correct3279, total10000\n",
      "epoch:0, batch:239, loss1.9100444316864014\n",
      "epoch:0, batch:239, loss1.9100444316864014\n",
      "acc33.07, correct3307, total10000\n",
      "acc33.07, correct3307, total10000\n",
      "epoch:0, batch:269, loss1.807741403579712\n",
      "epoch:0, batch:269, loss1.807741403579712\n",
      "acc33.42, correct3342, total10000\n",
      "acc33.42, correct3342, total10000\n",
      "epoch:0, batch:299, loss1.6367989778518677\n",
      "epoch:0, batch:299, loss1.6367989778518677\n",
      "acc36.85, correct3685, total10000\n",
      "acc36.85, correct3685, total10000\n",
      "epoch:0, batch:329, loss1.7609976530075073\n",
      "epoch:0, batch:329, loss1.7609976530075073\n",
      "acc35.39, correct3539, total10000\n",
      "acc35.39, correct3539, total10000\n",
      "epoch:0, batch:359, loss1.6976512670516968\n",
      "epoch:0, batch:359, loss1.6976512670516968\n",
      "acc38.06, correct3806, total10000\n",
      "acc38.06, correct3806, total10000\n",
      "epoch:0, batch:389, loss1.78276789188385\n",
      "epoch:0, batch:389, loss1.78276789188385\n",
      "acc38.90, correct3890, total10000\n",
      "acc38.90, correct3890, total10000\n",
      "epoch:0, batch:419, loss1.746019721031189\n",
      "epoch:0, batch:419, loss1.746019721031189\n",
      "acc39.29, correct3929, total10000\n",
      "acc39.29, correct3929, total10000\n",
      "epoch:0, batch:449, loss1.7083572149276733\n",
      "epoch:0, batch:449, loss1.7083572149276733\n",
      "acc39.25, correct3925, total10000\n",
      "acc39.25, correct3925, total10000\n",
      "epoch:0, batch:479, loss1.6012042760849\n",
      "epoch:0, batch:479, loss1.6012042760849\n",
      "acc40.19, correct4019, total10000\n",
      "acc40.19, correct4019, total10000\n",
      "epoch:1, batch:29, loss1.653387188911438\n",
      "epoch:1, batch:29, loss1.653387188911438\n",
      "acc38.26, correct3826, total10000\n",
      "acc38.26, correct3826, total10000\n",
      "epoch:1, batch:59, loss1.6654876470565796\n",
      "epoch:1, batch:59, loss1.6654876470565796\n",
      "acc40.56, correct4056, total10000\n",
      "acc40.56, correct4056, total10000\n",
      "epoch:1, batch:89, loss1.631699800491333\n",
      "epoch:1, batch:89, loss1.631699800491333\n",
      "acc39.21, correct3921, total10000\n",
      "acc39.21, correct3921, total10000\n",
      "epoch:1, batch:119, loss1.9054346084594727\n",
      "epoch:1, batch:119, loss1.9054346084594727\n",
      "acc40.81, correct4081, total10000\n",
      "acc40.81, correct4081, total10000\n",
      "epoch:1, batch:149, loss1.4842456579208374\n",
      "epoch:1, batch:149, loss1.4842456579208374\n",
      "acc41.21, correct4121, total10000\n",
      "acc41.21, correct4121, total10000\n",
      "epoch:1, batch:179, loss1.6068997383117676\n",
      "epoch:1, batch:179, loss1.6068997383117676\n",
      "acc39.10, correct3910, total10000\n",
      "acc39.10, correct3910, total10000\n",
      "epoch:1, batch:209, loss1.680021047592163\n",
      "epoch:1, batch:209, loss1.680021047592163\n",
      "acc43.29, correct4329, total10000\n",
      "acc43.29, correct4329, total10000\n",
      "epoch:1, batch:239, loss1.7747962474822998\n",
      "epoch:1, batch:239, loss1.7747962474822998\n",
      "acc43.65, correct4365, total10000\n",
      "acc43.65, correct4365, total10000\n",
      "epoch:1, batch:269, loss1.72721529006958\n",
      "epoch:1, batch:269, loss1.72721529006958\n",
      "acc40.86, correct4086, total10000\n",
      "acc40.86, correct4086, total10000\n",
      "epoch:1, batch:299, loss1.583766222000122\n",
      "epoch:1, batch:299, loss1.583766222000122\n",
      "acc42.64, correct4264, total10000\n",
      "acc42.64, correct4264, total10000\n",
      "epoch:1, batch:329, loss1.7613445520401\n",
      "epoch:1, batch:329, loss1.7613445520401\n",
      "acc41.09, correct4109, total10000\n",
      "acc41.09, correct4109, total10000\n",
      "epoch:1, batch:359, loss1.6625398397445679\n",
      "epoch:1, batch:359, loss1.6625398397445679\n",
      "acc42.01, correct4201, total10000\n",
      "acc42.01, correct4201, total10000\n",
      "epoch:1, batch:389, loss1.6619800329208374\n",
      "epoch:1, batch:389, loss1.6619800329208374\n",
      "acc44.82, correct4482, total10000\n",
      "acc44.82, correct4482, total10000\n",
      "epoch:1, batch:419, loss1.5450009107589722\n",
      "epoch:1, batch:419, loss1.5450009107589722\n",
      "acc41.89, correct4189, total10000\n",
      "acc41.89, correct4189, total10000\n",
      "epoch:1, batch:449, loss1.7305141687393188\n",
      "epoch:1, batch:449, loss1.7305141687393188\n",
      "acc43.89, correct4389, total10000\n",
      "acc43.89, correct4389, total10000\n",
      "epoch:1, batch:479, loss1.5886448621749878\n",
      "epoch:1, batch:479, loss1.5886448621749878\n",
      "acc43.75, correct4375, total10000\n",
      "acc43.75, correct4375, total10000\n",
      "epoch:2, batch:29, loss1.5143203735351562\n",
      "epoch:2, batch:29, loss1.5143203735351562\n",
      "acc44.30, correct4430, total10000\n",
      "acc44.30, correct4430, total10000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model = model.to(device)\n",
    "for _epoch in range(epochs):\n",
    "    for it_batch, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if (it_batch+1) % 30 == 0:\n",
    "            print(f'epoch:{_epoch}, batch:{it_batch}, loss{loss.item()}')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                correct_ = 0\n",
    "                total_ = 0\n",
    "\n",
    "                for it_batch, (images, labels) in enumerate(testloader):\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)                    \n",
    "                    \n",
    "                    outputs = model(images)\n",
    "\n",
    "                    predcits = torch.argmax(outputs, axis=1)\n",
    "                    correct_ += (labels == predcits).sum()\n",
    "                    total_ += predcits.shape[0]\n",
    "\n",
    "                acc = correct_/total_ * 100\n",
    "                print(f'acc{acc:.2f}, correct{correct_}, total{total_}')\n",
    "                \n",
    "                model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515af312",
   "metadata": {},
   "source": [
    "# evaluate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    correct_ = 0\n",
    "    total_ = 0\n",
    "\n",
    "    for it_batch, (images, labels) in enumerate(testloader):\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        predcits = torch.argmax(outputs, axis=1)\n",
    "        correct_ += (labels == predcits).sum()\n",
    "        total_ += predcits.shape[0]\n",
    "    \n",
    "    acc = correct_/total_ * 100\n",
    "    print(f'acc{acc:.2f}, correct{correct_}, total{total_}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3054959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e79d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
