{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1576e3",
   "metadata": {},
   "source": [
    "## python machine learning svm, pca, gbm\n",
    "!pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61b4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6ccc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f4d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54b0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x = iris_data.data\n",
    "iris_y = iris_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b1304",
   "metadata": {},
   "source": [
    "## 붓꽃의 꽃받침 길이, 꽃받침 너비 과 꽃잎의 길이, 꽃잎의 너비 에 대한 값 \n",
    "type(iris_x), iris_x.shape, iris_x[:10, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2c5fa",
   "metadata": {},
   "source": [
    "## class number 0- setosa, 1 - versicolor, 2 - virginica\n",
    "type(iris_y), iris_y.shape, iris_y[:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6974fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm 0~1 .. input mapping \n",
    "\n",
    "def norm_maxmin(data, out_min=0, out_max=255):\n",
    "    \n",
    "    gradient = (out_max - out_min) / (np.max(data) - np.min(data))\n",
    "    bias = out_min - np.min(data) * gradient\n",
    "    out = data * gradient + bias\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d88c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw, col \n",
    "for it_col in range(iris_x.shape[1]):\n",
    "    iris_x[:, it_col] = norm_maxmin(iris_x[:, it_col], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e25b3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135, 4), (135,), (15, 4), (15,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris_x, iris_y, test_size=0.1)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e55adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e462b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, batch_size, x_train.shape[1])\n",
    "y_train = y_train.reshape(-1, batch_size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74cdea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 15, 4), (9, 15))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c581e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy ary to tensor \n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f315166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor,\n",
       " torch.Size([9, 15, 4]),\n",
       " torch.float32,\n",
       " torch.Tensor,\n",
       " torch.Size([9, 15]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), x_train.shape, x_train.dtype, type(y_train), y_train.shape, y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f12731",
   "metadata": {},
   "source": [
    "# model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe4bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris_FCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Iris_FCN, self).__init__()\n",
    "        # \n",
    "        self.fc = nn.Linear(input_dim, 16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(8, output_dim)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o = self.fc(x)\n",
    "        o = self.relu(o)\n",
    "        o = self.fc2(o)\n",
    "        o = self.relu2(o)\n",
    "        o = self.fc3(o)\n",
    "        # o = self.relu3(o)\n",
    "        \n",
    "        # softmax\n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a62779",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_net = Iris_FCN(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0e163",
   "metadata": {},
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "summary(iris_net, input_size=((1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a507746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(iris_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b04d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 / 10000, Loss : 0.03439458832144737\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 2000 / 10000, Loss : 0.02870650216937065\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 3000 / 10000, Loss : 0.025904323905706406\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 4000 / 10000, Loss : 0.024247998371720314\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 5000 / 10000, Loss : 0.023209143429994583\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 6000 / 10000, Loss : 0.022868728265166283\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 7000 / 10000, Loss : 0.022511309012770653\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 8000 / 10000, Loss : 0.022217078134417534\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 9000 / 10000, Loss : 0.021986979991197586\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n",
      "Epoch 10000 / 10000, Loss : 0.017578132450580597\n",
      "correct 15 / total 15\n",
      "Accuracy of the model on test data: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "for e in range(epochs):\n",
    "    for b in range(x_train.shape[0]):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = iris_net(x_train[b])\n",
    "        \n",
    "        loss = criterion(output, y_train[b])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    if (e+1) % 1000 == 0:\n",
    "        print(f'Epoch {e+1} / {epochs}, Loss : {loss.item()}')\n",
    "        # accuracy \n",
    "        with torch.no_grad():\n",
    "            iris_net.eval()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            outputs = iris_net(x_test)\n",
    "            pred = torch.argmax(outputs, axis=1)\n",
    "            total = y_test.size(0)\n",
    "            correct = (pred == y_test).sum().item()\n",
    "            print(f'correct { correct } / total {total}')\n",
    "            print('Accuracy of the model on test data: {} %'.format(100 * correct / total))\n",
    "        iris_net.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c9862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
