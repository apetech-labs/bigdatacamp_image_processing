{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGyB4UHzTULJjJ06a9TQq8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"1c04926cf00644ac8c958377e93febe4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9cc56fd281524ad0aa648b9b5ad7acf9","IPY_MODEL_8cdc5621fa64498c8f9af54a2ca482ec","IPY_MODEL_d3291cde20504d3abb08ac4b6f84a693"],"layout":"IPY_MODEL_35c193f04fdc4c7d931ebf2d192fe968"}},"9cc56fd281524ad0aa648b9b5ad7acf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27f4ed26ea4e48f1be26db2ba321e231","placeholder":"​","style":"IPY_MODEL_89d62a3b88124de8ac1a8b8b554ce96a","value":"100%"}},"8cdc5621fa64498c8f9af54a2ca482ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_289e95bc4ff9498ca6d5ef9abdc1476a","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8cef39829a944c3af964fb58f7466d1","value":170498071}},"d3291cde20504d3abb08ac4b6f84a693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_405bf1adac4a47f2bef04dd8262b4392","placeholder":"​","style":"IPY_MODEL_17cff4c9a19f44e192794ac2b50a3aaf","value":" 170498071/170498071 [00:05&lt;00:00, 30276070.97it/s]"}},"35c193f04fdc4c7d931ebf2d192fe968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27f4ed26ea4e48f1be26db2ba321e231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89d62a3b88124de8ac1a8b8b554ce96a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"289e95bc4ff9498ca6d5ef9abdc1476a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8cef39829a944c3af964fb58f7466d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"405bf1adac4a47f2bef04dd8262b4392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17cff4c9a19f44e192794ac2b50a3aaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","\n","from tqdm.notebook import tqdm\n","\n","import matplotlib.pyplot as plt\n","\n","epochs = 60\n","batch_size = 256\n","learning_rate = 1e-3\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"o3Rs9eNLlpmy","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1679962338675,"user_tz":-540,"elapsed":4042,"user":{"displayName":"유인원","userId":"12609834608015613726"}},"outputId":"c6ada7a2-c846-4220-84cf-c88965153312"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["\n","\n","transform = transforms.Compose([\n","    ### flip, rotate, crop\n","    # numpy to tensor\n","     transforms.ToTensor(),\n","    # 0~255 --> -1 ~ 1\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ]\n",")\n","\n","trainset = torchvision.datasets.CIFAR10(root ='./data', train=True, download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root ='./data', train=False, download=True, transform=transform)\n","\n","train_dataloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle=True, num_workers=12)\n","test_dataloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"dke31RKofb5-","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["1c04926cf00644ac8c958377e93febe4","9cc56fd281524ad0aa648b9b5ad7acf9","8cdc5621fa64498c8f9af54a2ca482ec","d3291cde20504d3abb08ac4b6f84a693","35c193f04fdc4c7d931ebf2d192fe968","27f4ed26ea4e48f1be26db2ba321e231","89d62a3b88124de8ac1a8b8b554ce96a","289e95bc4ff9498ca6d5ef9abdc1476a","e8cef39829a944c3af964fb58f7466d1","405bf1adac4a47f2bef04dd8262b4392","17cff4c9a19f44e192794ac2b50a3aaf"]},"executionInfo":{"status":"ok","timestamp":1679962352255,"user_tz":-540,"elapsed":13588,"user":{"displayName":"유인원","userId":"12609834608015613726"}},"outputId":"a9cbe0c7-21f9-4fe9-c2f7-bf619a6d321b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c04926cf00644ac8c958377e93febe4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.name = \"SimpleCNN\"\n","        self.conv_layer = nn.Sequential(\n","#             nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3)),\n","            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3)),            \n","            nn.ReLU(inplace=True),\n","#             nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=2),\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3)),\n","            nn.ReLU(inplace=True),\n","            \n","            nn.MaxPool2d(kernel_size=2, stride=2), # subsampling\n","            \n","#             nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3)),\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3)),\n","            nn.ReLU(inplace=True),\n","#             nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=2),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3)),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.fc_layer = nn.Sequential(\n","#             nn.Dropout(p = 0.5),\n","            # 32*5*5 --> 64\n","            nn.Linear(32*5*5, 64),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Linear(64, 32),\n","            nn.ReLU(inplace=True),\n","            \n","            nn.Linear(32, 10)\n","        )\n","     \n","\n","    def forward(self, x):\n","        x = self.conv_layer(x)\n","        x = x.view(-1, 32*5*5)\n","        x = self.fc_layer(x)\n","        return x\n","\n","import torchsummary\n","model = SimpleCNN()\n","torchsummary.summary(model, (3, 32, 32), device = 'cpu')\n","model = model.to(device)\n"],"metadata":{"id":"qyxKL8mffd_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AlexNet(nn.Module) :\n","    def __init__(self) :\n","        super(AlexNet, self).__init__()\n","        self.name = \"AlexNet\"\n","        self.conv_layer1 = nn.Sequential(\n","            nn.Conv2d(3, 96, kernel_size=(4, 4)),\n","            nn.ReLU(inplace=True),\n","        )\n","        self.conv_layer2 = nn.Sequential(\n","            nn.Conv2d(96, 256, kernel_size=(5, 5), padding=(2, 2)),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.conv_layer3 = nn.Sequential(\n","            nn.Conv2d(256, 384, kernel_size=(3, 3), padding=(1, 1)),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 384, kernel_size=(3, 3), padding=(1, 1)),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=(3, 3), padding=(1, 1)),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.fc_layer1 = nn.Sequential(\n","            nn.Dropout(p = 0.5),\n","            nn.Linear(9216, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p = 0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(4096, 10)\n","        )\n","\n","    def forward(self, x) :\n","        output = self.conv_layer1(x)\n","        output = self.conv_layer2(output)\n","        output = self.conv_layer3(output)\n","        output = output.view(-1, 9216)\n","        output = self.fc_layer1(output)\n","        return output\n","    \n","import torchsummary\n","model = AlexNet()\n","torchsummary.summary(model, (3, 32, 32), device = 'cpu')\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4a0aJRojlEB","executionInfo":{"status":"ok","timestamp":1679962360949,"user_tz":-540,"elapsed":8698,"user":{"displayName":"유인원","userId":"12609834608015613726"}},"outputId":"d3d6df9e-17b4-4639-def4-e894bceaae91"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 96, 29, 29]           4,704\n","              ReLU-2           [-1, 96, 29, 29]               0\n","            Conv2d-3          [-1, 256, 29, 29]         614,656\n","              ReLU-4          [-1, 256, 29, 29]               0\n","         MaxPool2d-5          [-1, 256, 14, 14]               0\n","            Conv2d-6          [-1, 384, 14, 14]         885,120\n","              ReLU-7          [-1, 384, 14, 14]               0\n","            Conv2d-8          [-1, 384, 14, 14]       1,327,488\n","              ReLU-9          [-1, 384, 14, 14]               0\n","           Conv2d-10          [-1, 256, 14, 14]         884,992\n","             ReLU-11          [-1, 256, 14, 14]               0\n","        MaxPool2d-12            [-1, 256, 6, 6]               0\n","          Dropout-13                 [-1, 9216]               0\n","           Linear-14                 [-1, 4096]      37,752,832\n","             ReLU-15                 [-1, 4096]               0\n","          Dropout-16                 [-1, 4096]               0\n","           Linear-17                 [-1, 4096]      16,781,312\n","             ReLU-18                 [-1, 4096]               0\n","           Linear-19                   [-1, 10]          40,970\n","================================================================\n","Total params: 58,292,074\n","Trainable params: 58,292,074\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 8.26\n","Params size (MB): 222.37\n","Estimated Total Size (MB): 230.64\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["def test_accuracy(model, test_dataloader, batch_size):\n","  \n","    with torch.no_grad():\n","        model.eval()\n","        total_correct =0\n","        total_cnt = 0\n","\n","        for it_batch, data in enumerate(test_dataloader) :\n","            imges, labels = data\n","\n","            imges = imges.to(device)\n","            # gt --> 확률벡터로 변환\n","            labels = torch.eye(10)[labels]  \n","            labels = labels.to(device)\n","\n","            preds = model(imges)\n","\n","            t1 = torch.argmax(labels, dim=1)\n","            t2 = torch.argmax(preds, dim=1)\n","\n","            total_correct += (t1==t2).sum()\n","            total_cnt +=1\n","\n","    # prt('correct [%d] acc [%.2f] ', total_correct, total_correct/(total_cnt*batch_size))\n","\n","    return total_correct, total_cnt*batch_size\n"],"metadata":{"id":"R5OfhctQfhFZ","executionInfo":{"status":"ok","timestamp":1679962360950,"user_tz":-540,"elapsed":7,"user":{"displayName":"유인원","userId":"12609834608015613726"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","for it_epochs in range(epochs):\n","    train_loss = 0\n","    loss_cnt = 0\n","    for it_batch, data in enumerate(train_dataloader) :\n","\n","        model.train()\n","        imges, labels = data\n","\n","        imges = imges.to(device)\n","        labels = torch.eye(10)[labels]  # 확률벡터로 변환\n","        labels = labels.to(device)\n","\n","        preds = model(imges)\n","\n","        optimizer.zero_grad()\n","\n","        loss = criterion(preds, labels)\n","        train_loss += loss.item()\n","        loss_cnt += 1\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    prt = 'epoch %d train loss: %.2f' % (it_epochs, train_loss/loss_cnt)\n","    print(prt)\n","    total_correct, total_cnt = test_accuracy(model, test_dataloader, batch_size)\n","    prt = 'correct [%d] ##### acc [%.2f] ' % (total_correct, total_correct/total_cnt)\n","    print(prt)\n"],"metadata":{"id":"yMEn8X8ufPVE","colab":{"base_uri":"https://localhost:8080/","height":582},"executionInfo":{"status":"error","timestamp":1679962973028,"user_tz":-540,"elapsed":612083,"user":{"displayName":"유인원","userId":"12609834608015613726"}},"outputId":"c1a5abac-352e-4630-98a0-7fa8371e4ce1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0 train loss: 1.76\n","correct [5077] ##### acc [0.50] \n","epoch 1 train loss: 1.24\n","correct [6321] ##### acc [0.62] \n","epoch 2 train loss: 1.01\n","correct [6874] ##### acc [0.67] \n","epoch 3 train loss: 0.86\n","correct [7111] ##### acc [0.69] \n","epoch 4 train loss: 0.76\n","correct [7430] ##### acc [0.73] \n","epoch 5 train loss: 0.68\n","correct [7675] ##### acc [0.75] \n","epoch 6 train loss: 0.62\n","correct [7726] ##### acc [0.75] \n","epoch 7 train loss: 0.57\n","correct [7829] ##### acc [0.76] \n","epoch 8 train loss: 0.51\n","correct [7902] ##### acc [0.77] \n","epoch 9 train loss: 0.48\n","correct [7961] ##### acc [0.78] \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2a379efb9ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 확률벡터로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def draw_model_result(img_sample, label_sample, pred_sample):\n","    img_sample = img_sample.numpy().transpose([1, 2, 0])\n","    img_sample = img_sample / 2 + 0.5 # -1~1 --> 0~1\n","    title_ = 'gt[%s], pred[%s]' % (classes[torch.argmax(label_sample)], classes[torch.argmax(pred_sample)])\n","    plt.title(title_)\n","    plt.imshow(img_sample)\n","    plt.show()"],"metadata":{"id":"VfOLj6E0foTc","executionInfo":{"status":"aborted","timestamp":1679962973029,"user_tz":-540,"elapsed":8,"user":{"displayName":"유인원","userId":"12609834608015613726"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    model.eval()\n","\n","    data = next(iter(test_dataloader))\n","    imges, labels = data\n","\n","    imges = imges.to(device)\n","    # gt --> 확률벡터로 변환\n","    labels = torch.eye(10)[labels]  \n","    labels = labels.to(device)\n","\n","    preds = model(imges)\n","\n","imges = imges.cpu()\n","labels = labels.cpu()\n","preds = preds.cpu()\n","\n","\n","\n","for it_sample, img in enumerate(imges):\n","    draw_model_result(img, labels[it_sample], preds[it_sample])"],"metadata":{"id":"tVazZAWG8L1L","executionInfo":{"status":"aborted","timestamp":1679962973029,"user_tz":-540,"elapsed":8,"user":{"displayName":"유인원","userId":"12609834608015613726"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p9CNnCZnjumP"},"execution_count":null,"outputs":[]}]}